{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a278d3f",
   "metadata": {
    "papermill": {
     "duration": 0.003093,
     "end_time": "2023-07-27T11:00:10.342644",
     "exception": false,
     "start_time": "2023-07-27T11:00:10.339551",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## PropertyHub: 2.3 Scraping Condo Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1f65d2a",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-07-27T11:00:10.350084Z",
     "iopub.status.busy": "2023-07-27T11:00:10.349662Z",
     "iopub.status.idle": "2023-07-27T11:00:10.601741Z",
     "shell.execute_reply": "2023-07-27T11:00:10.600591Z"
    },
    "papermill": {
     "duration": 0.259054,
     "end_time": "2023-07-27T11:00:10.604571",
     "exception": false,
     "start_time": "2023-07-27T11:00:10.345517",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import requests\n",
    "from requests.adapters import HTTPAdapter, Retry\n",
    "from bs4 import BeautifulSoup\n",
    "from concurrent.futures import ThreadPoolExecutor, wait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5f916b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T11:00:10.612810Z",
     "iopub.status.busy": "2023-07-27T11:00:10.612161Z",
     "iopub.status.idle": "2023-07-27T11:00:10.775986Z",
     "shell.execute_reply": "2023-07-27T11:00:10.774733Z"
    },
    "papermill": {
     "duration": 0.171335,
     "end_time": "2023-07-27T11:00:10.778745",
     "exception": false,
     "start_time": "2023-07-27T11:00:10.607410",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GetLinks():\n",
    "    def __init__(self):\n",
    "        self.delay_time = 0.1\n",
    "        \n",
    "        self.rent_place_type = []\n",
    "        self.rent_place_name = []\n",
    "        self.rent_link_name = []\n",
    "        self.rent_condo_links = []\n",
    "        self.sale_place_type = []\n",
    "        self.sale_place_name = []\n",
    "        self.sale_link_name = []\n",
    "        self.sale_condo_links = []\n",
    "        \n",
    "        self.retries = 5\n",
    "        self.backoff = 1     # time-out = [0.5, 1, 2, 4, 8]\n",
    "        self.status_forcelist = [403, 500, 502, 503, 504]\n",
    "        self.timeout = (10, 10)\n",
    "        \n",
    "        # Initialize request session for retries and timeout\n",
    "        self.s = requests.Session()\n",
    "        retries = Retry(total=self.retries,\n",
    "                        backoff_factor=self.backoff,\n",
    "                        status_forcelist=self.status_forcelist)\n",
    "        self.s.mount('http://', HTTPAdapter(max_retries=retries))\n",
    "        self.s.mount('https://', HTTPAdapter(max_retries=retries))\n",
    "    \n",
    "    def import_shuffle_df(self, path, num):\n",
    "        self.location = pd.read_csv(path)\n",
    "        self.location = self.location[self.location['flag']==num]\n",
    "        \n",
    "    def get_condo_links(self, order):\n",
    "        df_place_link_name = self.location.iloc[order-1,:]\n",
    "        place_link_name = df_place_link_name['link_name']\n",
    "        \n",
    "        print(f\"Thread {order}: getting {df_place_link_name['num_rent']+df_place_link_name['num_sale']} links ...\")\n",
    "        \n",
    "        # Get for-rent links\n",
    "        if df_place_link_name['num_rent'] != 0:\n",
    "            try:\n",
    "                place_link = f'https://propertyhub.in.th/en/condo-for-rent/{place_link_name}'\n",
    "                # find max page number\n",
    "                soup = BeautifulSoup(self.s.get(place_link, timeout=self.timeout).content, \"html.parser\")\n",
    "                find_max_page = soup.find_all(\"ul\", {\"class\": \"sc-1p20b44-0 IoRRS\"})\n",
    "                try:\n",
    "                    max_page = int(find_max_page[0].find_all('li')[-2].a['aria-label'].split()[-1])\n",
    "                except:\n",
    "                    max_page = 1\n",
    "                page_links = [place_link + f'/{i+1}' if i!=0 else place_link for i in range(max_page)]\n",
    "                for page_link in page_links:\n",
    "                    soup = BeautifulSoup(self.s.get(page_link, timeout=self.timeout).content, \"html.parser\")\n",
    "                    find_condo_links = soup.select(\"a[href*='en/listings/']\")\n",
    "                    for link in find_condo_links:\n",
    "                        condo_link = 'https://propertyhub.in.th' + link['href']\n",
    "                        self.rent_place_type.append(df_place_link_name['place_type'])\n",
    "                        self.rent_place_name.append(df_place_link_name['place_name'])\n",
    "                        self.rent_link_name.append(df_place_link_name['link_name'])\n",
    "                        self.rent_condo_links.append(condo_link)\n",
    "                time.sleep(self.delay_time)\n",
    "            except:\n",
    "                print(f\"There is an invalid link: {place_link}\")\n",
    "\n",
    "        # Get for-sale links\n",
    "        if df_place_link_name['num_sale'] != 0:\n",
    "            try:\n",
    "                place_link = f'https://propertyhub.in.th/en/condo-for-sale/{place_link_name}'\n",
    "                # find max page number\n",
    "                soup = BeautifulSoup(self.s.get(place_link, timeout=self.timeout).content, \"html.parser\")\n",
    "                find_max_page = soup.find_all(\"ul\", {\"class\": \"sc-1p20b44-0 IoRRS\"})\n",
    "                try:\n",
    "                    max_page = int(find_max_page[0].find_all('li')[-2].a['aria-label'].split()[-1])\n",
    "                except:\n",
    "                    max_page = 1\n",
    "                page_links = [place_link + f'/{i+1}' if i!=0 else place_link for i in range(max_page)]\n",
    "                for page_link in page_links:\n",
    "                    soup = BeautifulSoup(self.s.get(page_link, timeout=self.timeout).content, \"html.parser\")\n",
    "                    find_condo_links = soup.select(\"a[href*='en/listings/']\")\n",
    "                    for link in find_condo_links:\n",
    "                        condo_link = 'https://propertyhub.in.th' + link['href']\n",
    "                        self.sale_place_type.append(df_place_link_name['place_type'])\n",
    "                        self.sale_place_name.append(df_place_link_name['place_name'])\n",
    "                        self.sale_link_name.append(df_place_link_name['link_name'])\n",
    "                        self.sale_condo_links.append(condo_link)\n",
    "                time.sleep(self.delay_time)\n",
    "            except:\n",
    "                print(f\"There is an invalid link: {place_link}\")\n",
    "\n",
    "        # Convert to df and remove duplicates\n",
    "        self.df_rent_condo_links = pd.DataFrame(self.rent_place_type,columns=['place_type'])\n",
    "        self.df_rent_condo_links['place_name'] = self.rent_place_name\n",
    "        self.df_rent_condo_links['link_name'] = self.rent_link_name\n",
    "        self.df_rent_condo_links['condo_link'] = self.rent_condo_links\n",
    "        self.df_rent_condo_links.drop_duplicates(subset=['condo_link'],keep='first',inplace=True, ignore_index=True)\n",
    "\n",
    "        self.df_sale_condo_links = pd.DataFrame(self.sale_place_type,columns=['place_type'])\n",
    "        self.df_sale_condo_links['place_name'] = self.sale_place_name\n",
    "        self.df_sale_condo_links['link_name'] = self.sale_link_name\n",
    "        self.df_sale_condo_links['condo_link'] = self.sale_condo_links\n",
    "        self.df_sale_condo_links.drop_duplicates(subset=['condo_link'],keep='first',inplace=True, ignore_index=True)\n",
    "\n",
    "        # Export\n",
    "        self.df_rent_condo_links.to_csv(f\"df_rent_condo_links_{order}.csv\",index=False)\n",
    "        self.df_sale_condo_links.to_csv(f\"df_sale_condo_links_{order}.csv\",index=False)\n",
    "        \n",
    "        print(f\"Thread {order}: finished !!!\")\n",
    "            \n",
    "    def join_df(self):\n",
    "        output_rent_files = glob.glob(os.getcwd()+'/df_rent*.csv')\n",
    "        output_sale_files = glob.glob(os.getcwd()+'/df_sale*.csv')\n",
    "        outputs_rent = [pd.read_csv(output_rent_file) for output_rent_file in output_rent_files]\n",
    "        outputs_sale = [pd.read_csv(output_sale_file) for output_sale_file in output_sale_files]\n",
    "\n",
    "        # Combine outputs\n",
    "        output_rent_all = outputs_rent[0]\n",
    "        for i in range(len(outputs_rent)-1):\n",
    "            output_rent_all = pd.concat([output_rent_all,outputs_rent[i+1]], axis=0, ignore_index=True)\n",
    "        output_sale_all = outputs_sale[0]\n",
    "        for i in range(len(outputs_sale)-1):\n",
    "            output_sale_all = pd.concat([output_sale_all,outputs_sale[i+1]], axis=0, ignore_index=True)\n",
    "            \n",
    "        # Drop duplicates\n",
    "        output_rent_all.drop_duplicates(subset=['condo_link'],keep='first',inplace=True, ignore_index=True)\n",
    "        output_sale_all.drop_duplicates(subset=['condo_link'],keep='first',inplace=True, ignore_index=True)\n",
    "        \n",
    "        # Print results\n",
    "        print(f'!!!!!! Finished Scraping Links !!!!!!')\n",
    "        print(f'for-rent data len: {len(output_rent_all)}')\n",
    "        print(f'for-sale data len: {len(output_sale_all)}')\n",
    "\n",
    "        # Export the combine result\n",
    "        output_rent_all.to_csv(f\"{datetime.now().strftime('%Y%m')}_rent_condo_links_3.csv\",index=False)\n",
    "        output_sale_all.to_csv(f\"{datetime.now().strftime('%Y%m')}_sale_condo_links_3.csv\",index=False)\n",
    "\n",
    "        # Delete all the unused files\n",
    "        [os.remove(output_rent_file) for output_rent_file in output_rent_files];\n",
    "        [os.remove(output_sale_file) for output_sale_file in output_sale_files];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0b3bc79",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T11:00:10.785877Z",
     "iopub.status.busy": "2023-07-27T11:00:10.785481Z",
     "iopub.status.idle": "2023-07-27T13:22:58.765457Z",
     "shell.execute_reply": "2023-07-27T13:22:58.764260Z"
    },
    "papermill": {
     "duration": 8567.986832,
     "end_time": "2023-07-27T13:22:58.768346",
     "exception": false,
     "start_time": "2023-07-27T11:00:10.781514",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of threads: 72\n",
      "Thread 1: getting 9945 links ...\n",
      "Thread 2: getting 9862 links ...\n",
      "Thread 3: getting 9827 links ...\n",
      "Thread 4: getting 9515 links ...\n",
      "Thread 5: getting 9270 links ...\n",
      "Thread 6: getting 9178 links ...\n",
      "Thread 7: getting 9094 links ...\n",
      "Thread 8: getting 9090 links ...\n",
      "There is an invalid link: https://propertyhub.in.th/en/condo-for-rent/royal-thai-army-nursing-college\n",
      "There is an invalid link: https://propertyhub.in.th/en/condo-for-sale/royal-thai-army-nursing-college\n",
      "Thread 7: finished !!!\n",
      "Thread 9: getting 9080 links ...\n",
      "There is an invalid link: https://propertyhub.in.th/en/condo-for-rent/chan-hun-bumpen-school\n",
      "There is an invalid link: https://propertyhub.in.th/en/condo-for-rent/bangkok-patana-school\n",
      "There is an invalid link: https://propertyhub.in.th/en/condo-for-rent/king-mongkut-s-university-of-technology-north-bangkok\n",
      "Thread 4: finished !!!\n",
      "Thread 10: getting 8907 links ...\n",
      "There is an invalid link: https://propertyhub.in.th/en/condo-for-rent/thailand-nursing-and-midwifery-council\n",
      "Thread 9: finished !!!\n",
      "Thread 11: getting 8898 links ...\n",
      "Thread 2: finished !!!\n",
      "Thread 12: getting 8731 links ...\n",
      "Thread 5: finished !!!\n",
      "Thread 13: getting 8631 links ...\n",
      "Thread 6: finished !!!\n",
      "Thread 14: getting 8590 links ...\n",
      "Thread 3: finished !!!\n",
      "Thread 15: getting 8309 links ...\n",
      "There is an invalid link: https://propertyhub.in.th/en/condo-for-rent/rajabhat-thonburi-university\n",
      "Thread 1: finished !!!\n",
      "Thread 16: getting 8132 links ...\n",
      "Thread 13: finished !!!\n",
      "Thread 17: getting 8065 links ...\n",
      "Thread 8: finished !!!\n",
      "Thread 18: getting 8038 links ...\n",
      "Thread 10: finished !!!\n",
      "Thread 19: getting 7954 links ...\n",
      "Thread 11: finished !!!\n",
      "Thread 20: getting 7590 links ...\n",
      "There is an invalid link: https://propertyhub.in.th/en/condo-for-rent/pathum-wan\n",
      "There is an invalid link: https://propertyhub.in.th/en/condo-for-rent/boromarajonani-college-of-nursing-bamrasnaradura\n",
      "Thread 15: finished !!!\n",
      "Thread 21: getting 7425 links ...\n",
      "Thread 14: finished !!!\n",
      "Thread 22: getting 7366 links ...\n",
      "Thread 19: finished !!!\n",
      "Thread 23: getting 7298 links ...\n",
      "Thread 12: finished !!!\n",
      "Thread 24: getting 7289 links ...\n",
      "Thread 16: finished !!!\n",
      "Thread 25: getting 7196 links ...\n",
      "Thread 17: finished !!!\n",
      "Thread 26: getting 7017 links ...\n",
      "Thread 20: finished !!!\n",
      "Thread 27: getting 6788 links ...\n",
      "There is an invalid link: https://propertyhub.in.th/en/condo-for-rent/din-daeng\n",
      "Thread 18: finished !!!\n",
      "Thread 28: getting 6714 links ...\n",
      "Thread 27: finished !!!\n",
      "Thread 29: getting 6557 links ...\n",
      "There is an invalid link: https://propertyhub.in.th/en/condo-for-rent/phet-kasem-road\n",
      "Thread 23: finished !!!\n",
      "Thread 30: getting 6485 links ...\n",
      "Thread 25: finished !!!\n",
      "Thread 31: getting 6460 links ...\n",
      "There is an invalid link: https://propertyhub.in.th/en/condo-for-rent/ratchaphak-technology-and-management-college\n",
      "Thread 26: finished !!!\n",
      "Thread 32: getting 6419 links ...\n",
      "Thread 22: finished !!!\n",
      "Thread 33: getting 6339 links ...\n",
      "Thread 21: finished !!!\n",
      "Thread 34: getting 6305 links ...\n",
      "Thread 24: finished !!!\n",
      "Thread 35: getting 6301 links ...\n",
      "Thread 28: finished !!!\n",
      "Thread 36: getting 6226 links ...\n",
      "There is an invalid link: https://propertyhub.in.th/en/condo-for-sale/rattanathibet-road--3\n",
      "Thread 30: finished !!!\n",
      "Thread 37: getting 6200 links ...\n",
      "Thread 29: finished !!!\n",
      "Thread 38: getting 5824 links ...\n",
      "Thread 32: finished !!!\n",
      "Thread 39: getting 5760 links ...\n",
      "Thread 31: finished !!!\n",
      "Thread 40: getting 5750 links ...\n",
      "Thread 33: finished !!!\n",
      "Thread 41: getting 5628 links ...\n",
      "Thread 36: finished !!!\n",
      "Thread 42: getting 5578 links ...\n",
      "Thread 34: finished !!!\n",
      "Thread 43: getting 5566 links ...\n",
      "Thread 35: finished !!!\n",
      "Thread 44: getting 5536 links ...\n",
      "Thread 38: finished !!!\n",
      "Thread 45: getting 5416 links ...\n",
      "Thread 39: finished !!!\n",
      "Thread 46: getting 5395 links ...\n",
      "Thread 37: finished !!!\n",
      "Thread 47: getting 5388 links ...\n",
      "Thread 41: finished !!!\n",
      "Thread 48: getting 5295 links ...\n",
      "Thread 42: finished !!!\n",
      "Thread 49: getting 5288 links ...\n",
      "Thread 40: finished !!!\n",
      "Thread 50: getting 5257 links ...\n",
      "Thread 43: finished !!!\n",
      "Thread 51: getting 5114 links ...\n",
      "Thread 44: finished !!!\n",
      "Thread 52: getting 5052 links ...\n",
      "Thread 46: finished !!!\n",
      "Thread 53: getting 4971 links ...\n",
      "Thread 45: finished !!!\n",
      "Thread 54: getting 4884 links ...\n",
      "Thread 48: finished !!!\n",
      "Thread 55: getting 4866 links ...\n",
      "Thread 47: finished !!!\n",
      "Thread 56: getting 4850 links ...\n",
      "Thread 49: finished !!!\n",
      "Thread 57: getting 4819 links ...\n",
      "Thread 50: finished !!!\n",
      "Thread 58: getting 4637 links ...\n",
      "Thread 52: finished !!!\n",
      "Thread 59: getting 4581 links ...\n",
      "Thread 55: finished !!!\n",
      "Thread 60: getting 4567 links ...\n",
      "Thread 51: finished !!!\n",
      "Thread 61: getting 4560 links ...\n",
      "Thread 54: finished !!!\n",
      "Thread 62: getting 4535 links ...\n",
      "Thread 53: finished !!!\n",
      "Thread 63: getting 4515 links ...\n",
      "Thread 56: finished !!!\n",
      "Thread 64: getting 4427 links ...\n",
      "Thread 59: finished !!!\n",
      "Thread 65: getting 4284 links ...\n",
      "Thread 58: finished !!!\n",
      "Thread 66: getting 4248 links ...\n",
      "Thread 57: finished !!!\n",
      "Thread 67: getting 4219 links ...\n",
      "Thread 63: finished !!!\n",
      "Thread 68: getting 4200 links ...\n",
      "Thread 61: finished !!!\n",
      "Thread 69: getting 4197 links ...\n",
      "Thread 60: finished !!!\n",
      "Thread 70: getting 4173 links ...\n",
      "Thread 62: finished !!!\n",
      "Thread 71: getting 4106 links ...\n",
      "Thread 64: finished !!!\n",
      "Thread 72: getting 4065 links ...\n",
      "Thread 66: finished !!!\n",
      "Thread 65: finished !!!\n",
      "Thread 68: finished !!!\n",
      "Thread 71: finished !!!\n",
      "Thread 67: finished !!!\n",
      "Thread 70: finished !!!\n",
      "Thread 69: finished !!!\n",
      "Thread 72: finished !!!\n",
      "!!!!!! Finished Scraping Links !!!!!!\n",
      "for-rent data len: 77581\n",
      "for-sale data len: 24597\n"
     ]
    }
   ],
   "source": [
    "num = 3\n",
    "input_path = '/kaggle/input/ph-1-getting-locations'\n",
    "file_name = 'locations.csv'\n",
    "locations = pd.read_csv(f\"{input_path}/{file_name}\")\n",
    "locations = locations[locations['flag']==num]\n",
    "\n",
    "thread_num = len(locations)\n",
    "print(f'Number of threads: {thread_num}')\n",
    "getlink_threads = [GetLinks() for _ in range(thread_num)]\n",
    "[getlink_thread.import_shuffle_df(f'{input_path}/{file_name}',num) for getlink_thread in getlink_threads]\n",
    "\n",
    "threadList = []\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    for i in range(thread_num):\n",
    "        threadList.append(executor.submit(getlink_threads[i].get_condo_links, i+1))\n",
    "wait(threadList);\n",
    "\n",
    "getlink_threads[0].join_df()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 8584.470641,
   "end_time": "2023-07-27T13:23:00.125057",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-07-27T10:59:55.654416",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
