{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a42fe5d",
   "metadata": {
    "papermill": {
     "duration": 0.00298,
     "end_time": "2023-07-27T15:53:55.159665",
     "exception": false,
     "start_time": "2023-07-27T15:53:55.156685",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## PropertyHub: 3.3 Scraping Condo Data (for-rent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8e4922b",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-07-27T15:53:55.166210Z",
     "iopub.status.busy": "2023-07-27T15:53:55.165858Z",
     "iopub.status.idle": "2023-07-27T15:53:55.395720Z",
     "shell.execute_reply": "2023-07-27T15:53:55.393880Z"
    },
    "papermill": {
     "duration": 0.23609,
     "end_time": "2023-07-27T15:53:55.398249",
     "exception": false,
     "start_time": "2023-07-27T15:53:55.162159",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import requests\n",
    "from requests.adapters import HTTPAdapter, Retry\n",
    "from bs4 import BeautifulSoup\n",
    "from concurrent.futures import ThreadPoolExecutor, wait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6655b040",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T15:53:55.405475Z",
     "iopub.status.busy": "2023-07-27T15:53:55.404856Z",
     "iopub.status.idle": "2023-07-27T15:53:55.440088Z",
     "shell.execute_reply": "2023-07-27T15:53:55.438364Z"
    },
    "papermill": {
     "duration": 0.041609,
     "end_time": "2023-07-27T15:53:55.442669",
     "exception": false,
     "start_time": "2023-07-27T15:53:55.401060",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ScrapeData():\n",
    "    def __init__(self):\n",
    "        self.delay_time = 0     # **** Please set this variable > 1 not to overload the server ****\n",
    "        self.condo_level_data = []\n",
    "        self.parse_count = 0\n",
    "        self.error_index = []\n",
    "        self.invalid_link_count = 0\n",
    "        self.retries = 5\n",
    "        self.backoff = 1     # time-out = [0.5, 1, 2, 4, 8]\n",
    "        self.status_forcelist = [403, 500, 502, 503, 504]\n",
    "        self.timeout = (10, 10)\n",
    "        \n",
    "        # Initialize request session for retries and timeout\n",
    "        self.s = requests.Session()\n",
    "        retries = Retry(total=self.retries,\n",
    "                        backoff_factor=self.backoff,\n",
    "                        status_forcelist=self.status_forcelist)\n",
    "        self.s.mount('http://', HTTPAdapter(max_retries=retries))\n",
    "        self.s.mount('https://', HTTPAdapter(max_retries=retries))\n",
    "        \n",
    "    def parse_data(self):\n",
    "        for condo_link in self.condo_links:\n",
    "            try:\n",
    "                page = self.s.get(condo_link, timeout=self.timeout)\n",
    "                soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "                # Parse condo details\n",
    "                post_name = soup.select(\"h1[class*='sc-14haut3-0 kiSLkD']\")[0].text.strip()\n",
    "                last_update_date = soup.select(\"div[class*='sc-ogfj7g-14 coaZDA']\")[0].text.strip().split()[-2]\n",
    "                last_update_time = soup.select(\"div[class*='sc-ogfj7g-14 coaZDA']\")[0].text.strip().split()[-1]\n",
    "                try:\n",
    "                    poster_name = soup.select(\"li[class*='sc-ves8oa-9 hCPUWp']\")[0].div.a.text\n",
    "                except:\n",
    "                    try:\n",
    "                        poster_name = soup.select(\"li[class*='sc-ves8oa-9 hCPUWp']\")[0].div.p.text\n",
    "                    except:\n",
    "                        poster_name = ''\n",
    "                poster_status = soup.select(\"li[class*='sc-ves8oa-9 hCPUWp']\")[0].div.div.text\n",
    "                # view_count = soup.select(\"div[class*='sc-ves8oa-0 hWLLWW']\")[0].text.strip().split()[-1]        # Cannot get view count as the page needs to load up\n",
    "                \n",
    "                if self.rent_flag == 1:\n",
    "                    price_unit = soup.select(\"div[class*='sc-152o12i-7 dKuoZx priceTag sc-s9r052-5 dvOoHM']\")[0].find_all('span')[-1].text\n",
    "                    if price_unit.lower().strip() == 'please contact':\n",
    "                        try:\n",
    "                            price = int(soup.select(\"div[class*='sc-152o12i-7 dKuoZx priceTag sc-s9r052-5 dvOoHM']\")[0].find_all('span')[1].text.split('THB')[0].replace(',',''))\n",
    "                            price_unit = soup.select(\"div[class*='sc-152o12i-7 dKuoZx priceTag sc-s9r052-5 dvOoHM']\")[0].find_all('span')[2].text.strip()\n",
    "                        except:\n",
    "                            price = 'please'\n",
    "                            price_unit = 'contact'\n",
    "                    else:\n",
    "                        price = int(soup.select(\"div[class*='sc-152o12i-7 dKuoZx priceTag sc-s9r052-5 dvOoHM']\")[0].find_all('span')[-2].text.split('THB')[0].replace(',',''))\n",
    "\n",
    "                    deposit = soup.select(\"li[class*='sc-s9r052-3 iJHhTM']\")[0].find_all('p')[-1].text.strip().split()[0]\n",
    "                    try:\n",
    "                        deposit_unit = soup.select(\"li[class*='sc-s9r052-3 iJHhTM']\")[0].find_all('p')[-1].text.strip().split()[1]\n",
    "                    except:\n",
    "                        deposit_unit = \"\"\n",
    "                    advance_payment = soup.select(\"li[class*='sc-s9r052-3 iJHhTM']\")[1].find_all('p')[-1].text.strip().split()[0]\n",
    "                    try:\n",
    "                        advance_payment_unit = soup.select(\"li[class*='sc-s9r052-3 iJHhTM']\")[1].find_all('p')[-1].text.strip().split()[1]\n",
    "                    except:\n",
    "                        advance_payment_unit = \"\"\n",
    "                else:\n",
    "                    price_unit = soup.select(\"div[class*='sc-152o12i-7 dKuoZx priceTag sc-s9r052-6 gRLtIb']\")[0].find_all('span')[-1].text\n",
    "                    if price_unit.lower().strip() == 'please contact':\n",
    "                        try:\n",
    "                            price = int(soup.select(\"div[class*='sc-152o12i-7 dKuoZx priceTag sc-s9r052-6 gRLtIb']\")[0].find_all('span')[1].text.split('THB')[0].replace(',',''))\n",
    "                            price_unit = soup.select(\"div[class*='sc-152o12i-7 dKuoZx priceTag sc-s9r052-6 gRLtIb']\")[0].find_all('span')[2].text.strip()\n",
    "                        except:\n",
    "                            price = 'please'\n",
    "                            price_unit = 'contact'\n",
    "                    else:\n",
    "                        price = int(soup.select(\"div[class*='sc-152o12i-7 dKuoZx priceTag sc-s9r052-6 gRLtIb']\")[0].find_all('span')[-2].text.split('THB')[0].replace(',',''))\n",
    "                    \n",
    "                    deposit = ''\n",
    "                    deposit_unit = ''\n",
    "                    advance_payment = ''\n",
    "                    advance_payment_unit = ''\n",
    "                    \n",
    "                room_info_header = [room_info.p.text.strip(':') for room_info in soup.select(\"li[class*='sc-s9r052-1 bLavUw']\")]\n",
    "                room_info_value = [room_info.span.text.strip() for room_info in soup.select(\"li[class*='sc-s9r052-1 bLavUw']\")]\n",
    "                find_room_description = soup.select(\"div[class*='sc-ves8oa-21 bBnKvP']\")\n",
    "                if len(find_room_description) == 0:\n",
    "                    room_description = []\n",
    "                else:\n",
    "                    room_description = find_room_description[0].text.strip()\n",
    "\n",
    "                room_amenities_have = [amen.text.strip() for amen in soup.select(\"div[class*='sc-1qj7qf1-1 czrvpe']\")[0].find_all('span')]\n",
    "                room_amenities_not_have = [amen.text.strip() for amen in soup.select(\"div[class*='sc-1qj7qf1-1 czrvpe']\")[0].find_all('strike')]\n",
    "\n",
    "                # Parse project details\n",
    "                project_details_attributes = [header.text.strip() for header in soup.select(\"table[class*='sc-7l0zor-1 jEPVvF']\")[0].find_all('th')]\n",
    "                project_details_values = []\n",
    "                for value in soup.select(\"table[class*='sc-7l0zor-1 jEPVvF']\")[0].find_all('td'):\n",
    "                    if len(value.find_all('li')) <= 1:\n",
    "                        project_details_values.append(value.text.strip())\n",
    "                    else:\n",
    "                        value_list = [v.text.strip() for v in value.find_all('li')]\n",
    "                        project_details_values.append(value_list)\n",
    "                facilities_have = [facil.text.strip() for facil in soup.select(\"div[class*='sc-vxzykp-0 dTLeQV sc-ogfj7g-18 sc-iv2rdv-17 bLEjbt citTje']\")[0].find_all('span')]\n",
    "                facilities_not_have = [facil.text.strip() for facil in soup.select(\"div[class*='sc-vxzykp-0 dTLeQV sc-ogfj7g-18 sc-iv2rdv-17 bLEjbt citTje']\")[0].find_all('strike')]\n",
    "\n",
    "                # Parse properties in nearby area\n",
    "                nearby_property_type = []\n",
    "                nearby_property_name = []\n",
    "                nearby_property_distance = []\n",
    "\n",
    "                blocks = soup.select(\"div[class*='sc-vxzykp-0 dNnjli sc-nnw194-1 bnkbhT']\")\n",
    "                blocks.extend(soup.select(\"div[class*='sc-vxzykp-0 dTLeQV sc-nnw194-1 bnkbhT']\"))\n",
    "\n",
    "                for block in blocks:\n",
    "                    for i,sub_block in enumerate(block.select(\"div[class*='row sc-nnw194-2 gAWLJy']\")):\n",
    "                        for prop in sub_block.select(\"a[class*='zoneTypeStyle']\"):\n",
    "                            nearby_property_type.append(block.find_all('h3')[i].text.strip())\n",
    "                            nearby_property_name.append(prop.text.strip().replace('Condo ',''))\n",
    "                            if len(sub_block.find_all('span'))==0:\n",
    "                                nearby_property_distance.append('')\n",
    "                            else:\n",
    "                                nearby_property_distance.append(sub_block.find_all('span')[0].text.strip())\n",
    "\n",
    "                self.condo_level_data.append([self.rent_flag,\n",
    "                                            condo_link,\n",
    "                                            post_name,\n",
    "                                            last_update_date,\n",
    "                                            last_update_time,\n",
    "                                            poster_name,\n",
    "                                            poster_status,\n",
    "                                            price,\n",
    "                                            price_unit,\n",
    "                                            deposit,\n",
    "                                            deposit_unit,\n",
    "                                            advance_payment,\n",
    "                                            advance_payment_unit,\n",
    "                                            room_info_header,\n",
    "                                            room_info_value,\n",
    "                                            room_description,\n",
    "                                            room_amenities_have,\n",
    "                                            room_amenities_not_have,\n",
    "                                            project_details_attributes,\n",
    "                                            project_details_values,\n",
    "                                            facilities_have,\n",
    "                                            facilities_not_have,\n",
    "                                            nearby_property_type,\n",
    "                                            nearby_property_name,\n",
    "                                            nearby_property_distance])\n",
    "\n",
    "                self.parse_count += 1\n",
    "                time.sleep(self.delay_time)\n",
    "                \n",
    "            except:\n",
    "                self.condo_level_data.append([])\n",
    "                if (page.url == 'https://propertyhub.in.th/en') or (len(soup.select(\"div[class*='sc-1552ugy-1 sc-1552ugy-5 kvqbdg eugViW']\")) != 0):\n",
    "                    self.invalid_link_count += 1 \n",
    "                    self.parse_count += 1\n",
    "                    continue\n",
    "                else:\n",
    "                    print(f'Error at {condo_link}')\n",
    "                    self.error_index.append(self.parse_count)\n",
    "                    self.parse_count += 1\n",
    "                    continue\n",
    "                \n",
    "    \n",
    "    def export_results(self):\n",
    "        condo_data = pd.DataFrame(self.condo_level_data)\n",
    "        col_names = ['rent_flag',\n",
    "                    'condo_link',\n",
    "                    'post_name',\n",
    "                    'last_update_date',\n",
    "                    'last_update_time',\n",
    "                    'poster_name',\n",
    "                    'poster_status',\n",
    "                    'price',\n",
    "                    'price_unit',\n",
    "                    'deposit',\n",
    "                    'deposit_unit',\n",
    "                    'advance_payment',\n",
    "                    'advance_payment_unit',\n",
    "                    'room_info_header',\n",
    "                    'room_info_value',\n",
    "                    'room_description',\n",
    "                    'room_amenities_have',\n",
    "                    'room_amenities_not_have',\n",
    "                    'project_details_attributes',\n",
    "                    'project_details_values',\n",
    "                    'facilities_have',\n",
    "                    'facilities_not_have',\n",
    "                    'nearby_property_type',\n",
    "                    'nearby_property_name',\n",
    "                    'nearby_property_distance']\n",
    "        \n",
    "        condo_data.columns = col_names\n",
    "        condo_data.to_csv(f\"condo_data_{self.order}.csv\",index=False)\n",
    "    \n",
    "    def main(self, df_links, order, rent_flag=1):\n",
    "        self.condo_links = df_links.iloc[:,3]\n",
    "        self.order = order\n",
    "        self.rent_flag = rent_flag   # 1 for-rent and 0 for-sale\n",
    "        \n",
    "        print(f'Thread {self.order}: Scraping for {len(self.condo_links)} links ...')\n",
    "        \n",
    "        self.parse_data()\n",
    "        self.export_results()\n",
    "        \n",
    "        if len(self.error_index) > 0:\n",
    "            print(f'Thread {self.order}: !!! Scraping completed ({len(self.error_index)} errors, {self.invalid_link_count} invalid links)')\n",
    "        else:\n",
    "            print(f'Thread {self.order}: !!! Scraping completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55d01f08",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T15:53:55.448624Z",
     "iopub.status.busy": "2023-07-27T15:53:55.448276Z",
     "iopub.status.idle": "2023-07-27T15:53:56.906345Z",
     "shell.execute_reply": "2023-07-27T15:53:56.904282Z"
    },
    "papermill": {
     "duration": 1.464505,
     "end_time": "2023-07-27T15:53:56.909564",
     "exception": false,
     "start_time": "2023-07-27T15:53:55.445059",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3rd batch: for-rent data len: 21834\n"
     ]
    }
   ],
   "source": [
    "# Once scraping condo links notebook is done, upload the generated output files to this notebook and update the input path\n",
    "path_1 = '/kaggle/input/ph-2-1-scraping-condo-links'\n",
    "df_rent_links_1 = pd.read_csv(f\"{path_1}/{datetime.now().strftime('%Y%m')}_rent_condo_links_1.csv\")\n",
    "\n",
    "path_2 = '/kaggle/input/ph-2-2-scraping-condo-links'\n",
    "df_rent_links_2 = pd.read_csv(f\"{path_2}/{datetime.now().strftime('%Y%m')}_rent_condo_links_2.csv\")\n",
    "\n",
    "path_3 = '/kaggle/input/ph-2-3-scraping-condo-links'\n",
    "df_rent_links_3 = pd.read_csv(f\"{path_3}/{datetime.now().strftime('%Y%m')}_rent_condo_links_3.csv\")\n",
    "\n",
    "path_4 = '/kaggle/input/ph-2-4-scraping-condo-links'\n",
    "df_rent_links_4 = pd.read_csv(f\"{path_4}/{datetime.now().strftime('%Y%m')}_rent_condo_links_4.csv\")\n",
    "\n",
    "df_rent_links = pd.concat([df_rent_links_1,df_rent_links_2,df_rent_links_3,df_rent_links_4], axis=0, ignore_index=True)\n",
    "df_rent_links.drop_duplicates(subset=['condo_link'],keep='first',inplace=True, ignore_index=True)\n",
    "\n",
    "# Dividing into groups\n",
    "rent_len = round(len(df_rent_links)/5)\n",
    "print(f'3rd batch: for-rent data len: {rent_len}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bd17f25",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T15:53:56.916612Z",
     "iopub.status.busy": "2023-07-27T15:53:56.916236Z",
     "iopub.status.idle": "2023-07-27T22:03:26.301392Z",
     "shell.execute_reply": "2023-07-27T22:03:26.299973Z"
    },
    "papermill": {
     "duration": 22169.394426,
     "end_time": "2023-07-27T22:03:26.306724",
     "exception": false,
     "start_time": "2023-07-27T15:53:56.912298",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread 33: Scraping for 1364 links ...\n",
      "Thread 34: Scraping for 1365 links ...\n",
      "Thread 35: Scraping for 1365 links ...\n",
      "Thread 36: Scraping for 1364 links ...\n",
      "Thread 37: Scraping for 1365 links ...\n",
      "Thread 38: Scraping for 1365 links ...\n",
      "Thread 39: Scraping for 1364 links ...\n",
      "Thread 40: Scraping for 1365 links ...\n",
      "Thread 37: !!! Scraping completed\n",
      "Thread 41: Scraping for 1365 links ...\n",
      "Thread 34: !!! Scraping completed\n",
      "Thread 42: Scraping for 1364 links ...\n",
      "Error at https://propertyhub.in.th/en/listings/luxury-style-1-bed-1-bath-good-view-good-location-mrt-sukhumvit-20-m-bts-asok-condo-for-rent-ashton-asoke-แอชตัน-อโศก---3574090\n",
      "Error at https://propertyhub.in.th/en/listings/️-update-today-for-rent-wind-sukhumvit-23-near-bts-asoke-please-inform-the-property-code-via-line-2304-301--afd50995---3712543\n",
      "Thread 35: !!! Scraping completed\n",
      "Thread 43: Scraping for 1365 links ...\n",
      "Thread 36: !!! Scraping completed\n",
      "Thread 44: Scraping for 1365 links ...\n",
      "Thread 33: !!! Scraping completed\n",
      "Thread 45: Scraping for 1364 links ...\n",
      "Thread 38: !!! Scraping completed\n",
      "Thread 46: Scraping for 1365 links ...\n",
      "Thread 40: !!! Scraping completed\n",
      "Thread 47: Scraping for 1365 links ...\n",
      "Thread 39: !!! Scraping completed (1 errors, 5 invalid links)\n",
      "Thread 48: Scraping for 1364 links ...\n",
      "Error at https://propertyhub.in.th/en/listings/for-rent-at-the-light-house-sathorn-charoen-nakhon-negotiable-at-m678-with-too---3803987\n",
      "Error at https://propertyhub.in.th/en/listings/condo-for-rent-the-address-asoke-fully-furnished-confirm-again-when-visit--a6aa08db---3066379\n",
      "Error at https://propertyhub.in.th/en/listings/for-rent-the-key-phaholyothin-34-1-bedroom-4th-floor-building-a-near-bts-senanikom-line-id-579gllfh---3777910\n",
      "Error at https://propertyhub.in.th/en/listings/1-br-condo-at-belle-grand-rama-9-near-mrt-phra-ram-9-id-882086--ac6a09b3---3831403\n",
      "Error at https://propertyhub.in.th/en/listings/condo-for-rent-harmony-living-sukhumvit-15-fully-furnished---3406350\n",
      "Error at https://propertyhub.in.th/en/listings/metro-sky-prachachuen--a555096b---3794594\n",
      "Error at https://propertyhub.in.th/en/listings/for-rent-life-ladprao-studio-44th-floor-building-a-near-bts-lad-phrao-intersection-line-id-579gllfh---3779986\n",
      "Error at https://propertyhub.in.th/en/listings/for-rent-life-asoke-rama-9-near-mrt-rama9--b443095f---3725045\n",
      "Error at https://propertyhub.in.th/en/listings/chateau-in-town-ratchada-36--abe609a4---3798522\n",
      "Error at https://propertyhub.in.th/en/listings/for-rent-lumpini-ville-ratburana-riverview-2-6th-floor-building-:-a-size-23-sq-m-studio-1-bathroom-1513---1945392\n",
      "Error at https://propertyhub.in.th/en/listings/for-rent-modiz-ratchada-32-1-bedroom-4th-floor-near-mrt-lat-phrao-line-id-579gllfh---3784220\n",
      "Error at https://propertyhub.in.th/en/listings/3-br-condo-at-belle-grand-rama-9-near-mrt-phra-ram-9-id-514958--b75c09d4---3831571\n",
      "Error at https://propertyhub.in.th/en/listings/regent-home6-prachachuen---3803061\n",
      "Thread 45: !!! Scraping completed (3 errors, 4 invalid links)\n",
      "Thread 44: !!! Scraping completed (2 errors, 2 invalid links)\n",
      "Thread 46: !!! Scraping completed\n",
      "Thread 42: !!! Scraping completed (1 errors, 3 invalid links)\n",
      "Thread 41: !!! Scraping completed (3 errors, 4 invalid links)\n",
      "Thread 43: !!! Scraping completed (2 errors, 2 invalid links)\n",
      "Thread 47: !!! Scraping completed\n",
      "Thread 48: !!! Scraping completed (3 errors, 1 invalid links)\n"
     ]
    }
   ],
   "source": [
    "# Scraping for-rent condo data\n",
    "rent_group_num = 80\n",
    "rent_links = []\n",
    "for i in range(rent_group_num):\n",
    "    start = round(i*len(df_rent_links)/rent_group_num)\n",
    "    end = round((i+1)*len(df_rent_links)/rent_group_num)\n",
    "    rent_links.append(df_rent_links.iloc[start:end,:])\n",
    "\n",
    "rent_thread_num = 16\n",
    "rent_scrape_threads = [ScrapeData() for _ in range(rent_thread_num)]\n",
    "rent_threadList = []\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    for i in range(rent_thread_num):\n",
    "        rent_threadList.append(executor.submit(rent_scrape_threads[i].main, rent_links[i+32], i+1+32, 1))\n",
    "wait(rent_threadList);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d8b3bae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T22:03:26.318092Z",
     "iopub.status.busy": "2023-07-27T22:03:26.317625Z",
     "iopub.status.idle": "2023-07-27T22:03:28.549522Z",
     "shell.execute_reply": "2023-07-27T22:03:28.547831Z"
    },
    "papermill": {
     "duration": 2.240878,
     "end_time": "2023-07-27T22:03:28.552508",
     "exception": false,
     "start_time": "2023-07-27T22:03:26.311630",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total output length: 21769\n"
     ]
    }
   ],
   "source": [
    "# Read all files in the output folder\n",
    "output_files = glob.glob(f\"{os.getcwd()}/condo_data*.csv\")\n",
    "outputs = [pd.read_csv(f'{output_file}') for output_file in output_files]\n",
    "\n",
    "# Combine outputs\n",
    "output_all = outputs[0]\n",
    "for i in range(len(outputs)-1):\n",
    "    output_all = pd.concat([output_all,outputs[i+1]], axis=0, ignore_index=True)\n",
    "\n",
    "# Drop empty rows resulting from errors from scraping\n",
    "output_all.dropna(subset=['post_name'], axis=0, inplace=True)\n",
    "output_all.reset_index(inplace=True, drop=True)\n",
    "output = output_all\n",
    "\n",
    "# Export the combine result\n",
    "output.to_csv(f\"{datetime.now().strftime('%Y%m')}_condo_data_3.csv\",index=False)\n",
    "\n",
    "# Delete all the unused files\n",
    "[os.remove(output_file) for output_file in output_files];\n",
    "\n",
    "# Show results\n",
    "print(f'Total output length: {len(output)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 22187.460812,
   "end_time": "2023-07-27T22:03:30.415135",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-07-27T15:53:42.954323",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
