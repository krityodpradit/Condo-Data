{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f15b78a",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-07-27T15:53:52.180411Z",
     "iopub.status.busy": "2023-07-27T15:53:52.180039Z",
     "iopub.status.idle": "2023-07-27T15:53:52.343869Z",
     "shell.execute_reply": "2023-07-27T15:53:52.342763Z"
    },
    "papermill": {
     "duration": 0.170954,
     "end_time": "2023-07-27T15:53:52.346657",
     "exception": false,
     "start_time": "2023-07-27T15:53:52.175703",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import requests\n",
    "from requests.adapters import HTTPAdapter, Retry\n",
    "from bs4 import BeautifulSoup\n",
    "from concurrent.futures import ThreadPoolExecutor, wait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2262fd97",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T15:53:52.353156Z",
     "iopub.status.busy": "2023-07-27T15:53:52.352621Z",
     "iopub.status.idle": "2023-07-27T15:53:52.386986Z",
     "shell.execute_reply": "2023-07-27T15:53:52.385783Z"
    },
    "papermill": {
     "duration": 0.041758,
     "end_time": "2023-07-27T15:53:52.390896",
     "exception": false,
     "start_time": "2023-07-27T15:53:52.349138",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ScrapeData():\n",
    "    def __init__(self):\n",
    "        self.delay_time = 0     # **** Please set this variable > 1 not to overload the server ****\n",
    "        self.condo_level_data = []\n",
    "        self.parse_count = 0\n",
    "        self.error_index = []\n",
    "        self.invalid_link_count = 0\n",
    "        self.retries = 5\n",
    "        self.backoff = 1     # time-out = [0.5, 1, 2, 4, 8]\n",
    "        self.status_forcelist = [403, 500, 502, 503, 504]\n",
    "        self.timeout = (10, 10)\n",
    "        \n",
    "        # Initialize request session for retries and timeout\n",
    "        self.s = requests.Session()\n",
    "        retries = Retry(total=self.retries,\n",
    "                        backoff_factor=self.backoff,\n",
    "                        status_forcelist=self.status_forcelist)\n",
    "        self.s.mount('http://', HTTPAdapter(max_retries=retries))\n",
    "        self.s.mount('https://', HTTPAdapter(max_retries=retries))\n",
    "        \n",
    "    def parse_data(self):\n",
    "        for condo_link in self.condo_links:\n",
    "            try:\n",
    "                page = self.s.get(condo_link, timeout=self.timeout)\n",
    "                soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "                # Parse condo details\n",
    "                post_name = soup.select(\"h1[class*='sc-14haut3-0 kiSLkD']\")[0].text.strip()\n",
    "                last_update_date = soup.select(\"div[class*='sc-ogfj7g-14 coaZDA']\")[0].text.strip().split()[-2]\n",
    "                last_update_time = soup.select(\"div[class*='sc-ogfj7g-14 coaZDA']\")[0].text.strip().split()[-1]\n",
    "                try:\n",
    "                    poster_name = soup.select(\"li[class*='sc-ves8oa-9 hCPUWp']\")[0].div.a.text\n",
    "                except:\n",
    "                    try:\n",
    "                        poster_name = soup.select(\"li[class*='sc-ves8oa-9 hCPUWp']\")[0].div.p.text\n",
    "                    except:\n",
    "                        poster_name = ''\n",
    "                poster_status = soup.select(\"li[class*='sc-ves8oa-9 hCPUWp']\")[0].div.div.text\n",
    "                # view_count = soup.select(\"div[class*='sc-ves8oa-0 hWLLWW']\")[0].text.strip().split()[-1]        # Cannot get view count as the page needs to load up\n",
    "                \n",
    "                if self.rent_flag == 1:\n",
    "                    price_unit = soup.select(\"div[class*='sc-152o12i-7 dKuoZx priceTag sc-s9r052-5 dvOoHM']\")[0].find_all('span')[-1].text\n",
    "                    if price_unit.lower().strip() == 'please contact':\n",
    "                        try:\n",
    "                            price = int(soup.select(\"div[class*='sc-152o12i-7 dKuoZx priceTag sc-s9r052-5 dvOoHM']\")[0].find_all('span')[1].text.split('THB')[0].replace(',',''))\n",
    "                            price_unit = soup.select(\"div[class*='sc-152o12i-7 dKuoZx priceTag sc-s9r052-5 dvOoHM']\")[0].find_all('span')[2].text.strip()\n",
    "                        except:\n",
    "                            price = 'please'\n",
    "                            price_unit = 'contact'\n",
    "                    else:\n",
    "                        price = int(soup.select(\"div[class*='sc-152o12i-7 dKuoZx priceTag sc-s9r052-5 dvOoHM']\")[0].find_all('span')[-2].text.split('THB')[0].replace(',',''))\n",
    "\n",
    "                    deposit = soup.select(\"li[class*='sc-s9r052-3 iJHhTM']\")[0].find_all('p')[-1].text.strip().split()[0]\n",
    "                    try:\n",
    "                        deposit_unit = soup.select(\"li[class*='sc-s9r052-3 iJHhTM']\")[0].find_all('p')[-1].text.strip().split()[1]\n",
    "                    except:\n",
    "                        deposit_unit = \"\"\n",
    "                    advance_payment = soup.select(\"li[class*='sc-s9r052-3 iJHhTM']\")[1].find_all('p')[-1].text.strip().split()[0]\n",
    "                    try:\n",
    "                        advance_payment_unit = soup.select(\"li[class*='sc-s9r052-3 iJHhTM']\")[1].find_all('p')[-1].text.strip().split()[1]\n",
    "                    except:\n",
    "                        advance_payment_unit = \"\"\n",
    "                else:\n",
    "                    price_unit = soup.select(\"div[class*='sc-152o12i-7 dKuoZx priceTag sc-s9r052-6 gRLtIb']\")[0].find_all('span')[-1].text\n",
    "                    if price_unit.lower().strip() == 'please contact':\n",
    "                        try:\n",
    "                            price = int(soup.select(\"div[class*='sc-152o12i-7 dKuoZx priceTag sc-s9r052-6 gRLtIb']\")[0].find_all('span')[1].text.split('THB')[0].replace(',',''))\n",
    "                            price_unit = soup.select(\"div[class*='sc-152o12i-7 dKuoZx priceTag sc-s9r052-6 gRLtIb']\")[0].find_all('span')[2].text.strip()\n",
    "                        except:\n",
    "                            price = 'please'\n",
    "                            price_unit = 'contact'\n",
    "                    else:\n",
    "                        price = int(soup.select(\"div[class*='sc-152o12i-7 dKuoZx priceTag sc-s9r052-6 gRLtIb']\")[0].find_all('span')[-2].text.split('THB')[0].replace(',',''))\n",
    "                    \n",
    "                    deposit = ''\n",
    "                    deposit_unit = ''\n",
    "                    advance_payment = ''\n",
    "                    advance_payment_unit = ''\n",
    "                    \n",
    "                room_info_header = [room_info.p.text.strip(':') for room_info in soup.select(\"li[class*='sc-s9r052-1 bLavUw']\")]\n",
    "                room_info_value = [room_info.span.text.strip() for room_info in soup.select(\"li[class*='sc-s9r052-1 bLavUw']\")]\n",
    "                find_room_description = soup.select(\"div[class*='sc-ves8oa-21 bBnKvP']\")\n",
    "                if len(find_room_description) == 0:\n",
    "                    room_description = []\n",
    "                else:\n",
    "                    room_description = find_room_description[0].text.strip()\n",
    "\n",
    "                room_amenities_have = [amen.text.strip() for amen in soup.select(\"div[class*='sc-1qj7qf1-1 czrvpe']\")[0].find_all('span')]\n",
    "                room_amenities_not_have = [amen.text.strip() for amen in soup.select(\"div[class*='sc-1qj7qf1-1 czrvpe']\")[0].find_all('strike')]\n",
    "\n",
    "                # Parse project details\n",
    "                project_details_attributes = [header.text.strip() for header in soup.select(\"table[class*='sc-7l0zor-1 jEPVvF']\")[0].find_all('th')]\n",
    "                project_details_values = []\n",
    "                for value in soup.select(\"table[class*='sc-7l0zor-1 jEPVvF']\")[0].find_all('td'):\n",
    "                    if len(value.find_all('li')) <= 1:\n",
    "                        project_details_values.append(value.text.strip())\n",
    "                    else:\n",
    "                        value_list = [v.text.strip() for v in value.find_all('li')]\n",
    "                        project_details_values.append(value_list)\n",
    "                facilities_have = [facil.text.strip() for facil in soup.select(\"div[class*='sc-vxzykp-0 dTLeQV sc-ogfj7g-18 sc-iv2rdv-17 bLEjbt citTje']\")[0].find_all('span')]\n",
    "                facilities_not_have = [facil.text.strip() for facil in soup.select(\"div[class*='sc-vxzykp-0 dTLeQV sc-ogfj7g-18 sc-iv2rdv-17 bLEjbt citTje']\")[0].find_all('strike')]\n",
    "\n",
    "                # Parse properties in nearby area\n",
    "                nearby_property_type = []\n",
    "                nearby_property_name = []\n",
    "                nearby_property_distance = []\n",
    "\n",
    "                blocks = soup.select(\"div[class*='sc-vxzykp-0 dNnjli sc-nnw194-1 bnkbhT']\")\n",
    "                blocks.extend(soup.select(\"div[class*='sc-vxzykp-0 dTLeQV sc-nnw194-1 bnkbhT']\"))\n",
    "\n",
    "                for block in blocks:\n",
    "                    for i,sub_block in enumerate(block.select(\"div[class*='row sc-nnw194-2 gAWLJy']\")):\n",
    "                        for prop in sub_block.select(\"a[class*='zoneTypeStyle']\"):\n",
    "                            nearby_property_type.append(block.find_all('h3')[i].text.strip())\n",
    "                            nearby_property_name.append(prop.text.strip().replace('Condo ',''))\n",
    "                            if len(sub_block.find_all('span'))==0:\n",
    "                                nearby_property_distance.append('')\n",
    "                            else:\n",
    "                                nearby_property_distance.append(sub_block.find_all('span')[0].text.strip())\n",
    "\n",
    "                self.condo_level_data.append([self.rent_flag,\n",
    "                                            condo_link,\n",
    "                                            post_name,\n",
    "                                            last_update_date,\n",
    "                                            last_update_time,\n",
    "                                            poster_name,\n",
    "                                            poster_status,\n",
    "                                            price,\n",
    "                                            price_unit,\n",
    "                                            deposit,\n",
    "                                            deposit_unit,\n",
    "                                            advance_payment,\n",
    "                                            advance_payment_unit,\n",
    "                                            room_info_header,\n",
    "                                            room_info_value,\n",
    "                                            room_description,\n",
    "                                            room_amenities_have,\n",
    "                                            room_amenities_not_have,\n",
    "                                            project_details_attributes,\n",
    "                                            project_details_values,\n",
    "                                            facilities_have,\n",
    "                                            facilities_not_have,\n",
    "                                            nearby_property_type,\n",
    "                                            nearby_property_name,\n",
    "                                            nearby_property_distance])\n",
    "\n",
    "                self.parse_count += 1\n",
    "                time.sleep(self.delay_time)\n",
    "                \n",
    "            except:\n",
    "                self.condo_level_data.append([])\n",
    "                if (page.url == 'https://propertyhub.in.th/en') or (len(soup.select(\"div[class*='sc-1552ugy-1 sc-1552ugy-5 kvqbdg eugViW']\")) != 0):\n",
    "                    self.invalid_link_count += 1 \n",
    "                    self.parse_count += 1\n",
    "                    continue\n",
    "                else:\n",
    "                    print(f'Error at {condo_link}')\n",
    "                    self.error_index.append(self.parse_count)\n",
    "                    self.parse_count += 1\n",
    "                    continue\n",
    "                \n",
    "    \n",
    "    def export_results(self):\n",
    "        condo_data = pd.DataFrame(self.condo_level_data)\n",
    "        col_names = ['rent_flag',\n",
    "                    'condo_link',\n",
    "                    'post_name',\n",
    "                    'last_update_date',\n",
    "                    'last_update_time',\n",
    "                    'poster_name',\n",
    "                    'poster_status',\n",
    "                    'price',\n",
    "                    'price_unit',\n",
    "                    'deposit',\n",
    "                    'deposit_unit',\n",
    "                    'advance_payment',\n",
    "                    'advance_payment_unit',\n",
    "                    'room_info_header',\n",
    "                    'room_info_value',\n",
    "                    'room_description',\n",
    "                    'room_amenities_have',\n",
    "                    'room_amenities_not_have',\n",
    "                    'project_details_attributes',\n",
    "                    'project_details_values',\n",
    "                    'facilities_have',\n",
    "                    'facilities_not_have',\n",
    "                    'nearby_property_type',\n",
    "                    'nearby_property_name',\n",
    "                    'nearby_property_distance']\n",
    "        \n",
    "        condo_data.columns = col_names\n",
    "        condo_data.to_csv(f\"condo_data_{self.order}.csv\",index=False)\n",
    "    \n",
    "    def main(self, df_links, order, rent_flag=1):\n",
    "        self.condo_links = df_links.iloc[:,3]\n",
    "        self.order = order\n",
    "        self.rent_flag = rent_flag   # 1 for-rent and 0 for-sale\n",
    "        \n",
    "        print(f'Thread {self.order}: Scraping for {len(self.condo_links)} links ...')\n",
    "        \n",
    "        self.parse_data()\n",
    "        self.export_results()\n",
    "        \n",
    "        if len(self.error_index) > 0:\n",
    "            print(f'Thread {self.order}: !!! Scraping completed ({len(self.error_index)} errors, {self.invalid_link_count} invalid links)')\n",
    "        else:\n",
    "            print(f'Thread {self.order}: !!! Scraping completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc7a774b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T15:53:52.396869Z",
     "iopub.status.busy": "2023-07-27T15:53:52.396294Z",
     "iopub.status.idle": "2023-07-27T15:53:54.351662Z",
     "shell.execute_reply": "2023-07-27T15:53:54.350655Z"
    },
    "papermill": {
     "duration": 1.960705,
     "end_time": "2023-07-27T15:53:54.353926",
     "exception": false,
     "start_time": "2023-07-27T15:53:52.393221",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4th batch: for-rent data len: 21834\n"
     ]
    }
   ],
   "source": [
    "# Once scraping condo links notebook is done, upload the generated output files to this notebook and update the input path\n",
    "path_1 = '/kaggle/input/ph-2-1-scraping-condo-links'\n",
    "df_rent_links_1 = pd.read_csv(f\"{path_1}/{datetime.now().strftime('%Y%m')}_rent_condo_links_1.csv\")\n",
    "\n",
    "path_2 = '/kaggle/input/ph-2-2-scraping-condo-links'\n",
    "df_rent_links_2 = pd.read_csv(f\"{path_2}/{datetime.now().strftime('%Y%m')}_rent_condo_links_2.csv\")\n",
    "\n",
    "path_3 = '/kaggle/input/ph-2-3-scraping-condo-links'\n",
    "df_rent_links_3 = pd.read_csv(f\"{path_3}/{datetime.now().strftime('%Y%m')}_rent_condo_links_3.csv\")\n",
    "\n",
    "path_4 = '/kaggle/input/ph-2-4-scraping-condo-links'\n",
    "df_rent_links_4 = pd.read_csv(f\"{path_4}/{datetime.now().strftime('%Y%m')}_rent_condo_links_4.csv\")\n",
    "\n",
    "df_rent_links = pd.concat([df_rent_links_1,df_rent_links_2,df_rent_links_3,df_rent_links_4], axis=0, ignore_index=True)\n",
    "df_rent_links.drop_duplicates(subset=['condo_link'],keep='first',inplace=True, ignore_index=True)\n",
    "\n",
    "# Dividing into groups\n",
    "rent_len = round(len(df_rent_links)/5)\n",
    "print(f'4th batch: for-rent data len: {rent_len}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fee9d0ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T15:53:54.360174Z",
     "iopub.status.busy": "2023-07-27T15:53:54.359840Z",
     "iopub.status.idle": "2023-07-27T21:43:11.088482Z",
     "shell.execute_reply": "2023-07-27T21:43:11.087419Z"
    },
    "papermill": {
     "duration": 20956.737841,
     "end_time": "2023-07-27T21:43:11.094215",
     "exception": false,
     "start_time": "2023-07-27T15:53:54.356374",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread 65: Scraping for 1364 links ...Thread 66: Scraping for 1365 links ...\n",
      "\n",
      "Thread 67: Scraping for 1365 links ...\n",
      "Thread 68: Scraping for 1364 links ...\n",
      "Thread 69: Scraping for 1365 links ...\n",
      "Thread 70: Scraping for 1365 links ...\n",
      "Thread 71: Scraping for 1364 links ...\n",
      "Thread 72: Scraping for 1365 links ...\n",
      "Error at https://propertyhub.in.th/en/listings/lumpini-ram44-size-64-sq-m-2-beds-14-b-fl-17-000-baht-094-549-4104---3584700\n",
      "Thread 72: !!! Scraping completed\n",
      "Thread 73: Scraping for 1364 links ...\n",
      "Thread 67: !!! Scraping completed\n",
      "Thread 74: Scraping for 1365 links ...\n",
      "Thread 68: !!! Scraping completed\n",
      "Thread 75: Scraping for 1365 links ...\n",
      "Thread 69: !!! Scraping completed (1 errors, 1 invalid links)\n",
      "Thread 76: Scraping for 1364 links ...\n",
      "Thread 71: !!! Scraping completed\n",
      "Thread 77: Scraping for 1365 links ...\n",
      "Error at https://propertyhub.in.th/en/listings/park-ramindra--a19e08b2---3818978\n",
      "Error at https://propertyhub.in.th/en/listings/the-origin-phahol-saphanmai-for-rent-12000-thb---3118736\n",
      "Thread 66: !!! Scraping completed\n",
      "Thread 78: Scraping for 1365 links ...\n",
      "Thread 70: !!! Scraping completed\n",
      "Thread 79: Scraping for 1364 links ...\n",
      "Thread 65: !!! Scraping completed\n",
      "Thread 80: Scraping for 1365 links ...\n",
      "Error at https://propertyhub.in.th/en/listings/for-rent-lumpini-condo-town-chonburi-sukhumvit-1-bed-21-sq-m-6th-floor---1862669\n",
      "Error at https://propertyhub.in.th/en/listings/g-3818-中国客户，请加微信。-在联系方式的旁边-for-rent-the-kith-tiwanon-line️-condopremium️---1234863\n",
      "Error at https://propertyhub.in.th/en/listings/g-2735-中国客户，请加微信。-在联系方式的旁边-for-rent-the-kith-tiwanon-line️-condopremium️---925396\n",
      "Error at https://propertyhub.in.th/en/listings/lumpini-township-rangsit-klong1--9720089f---3131113\n",
      "Error at https://propertyhub.in.th/en/listings/punna-cmu-4-for-rent-13-500-baht-doi-suthep-view-tel-082-3899314-khun-boo--c7e60ac1---3741704\n",
      "Error at https://propertyhub.in.th/en/listings/unio-rama-2-thakham-condomidium---3367531\n",
      "Error at https://propertyhub.in.th/en/listings/for-rent-lumpini-park-nawamin-sriburapha-1-bedroom-7th-floor-building-a1-near-intrarak-market-line-id-316qhucz---3773235\n",
      "Error at https://propertyhub.in.th/en/listings/dl23070648-condo-for-rent-lumpini-ville-onnut-phatthanakan-near-ready-to-move-in-call-urgently-0842740999-lineid-655ebbvc---3834859\n",
      "Error at https://propertyhub.in.th/en/listings/️condo-next-to-bts-saphan-mai-very-good-price️-reach-condo-phaholyothin-52-starting-at-7-500-baht-month---3590777\n",
      "Error at https://propertyhub.in.th/en/listings/palm-sea-view-20f-studio-thb15-000-month彡---3825420\n",
      "Error at https://propertyhub.in.th/en/listings/amazing-high-rise-1-br-condo-at-life-sukhumvit-48-near-bts-phra-khanong-id-329212---3837172\n",
      "Error at https://propertyhub.in.th/en/listings/niche-mono-mega-space-bangna-condo-for-rent-line-mintocondo---3282096\n",
      "Error at https://propertyhub.in.th/en/listings/condo-for-rent-lumpini-ville-on-nut-phatthanakan--a9d0092d---3041125\n",
      "Error at https://propertyhub.in.th/en/listings/studio-condo-at-sukhumvit-plus-near-bts-phra-khanong-id-510178--b5500a12---3565124\n",
      "Error at https://propertyhub.in.th/en/listings/punna-cmu-4-for-rent-13-500-baht-doi-suthep-view-tel-082-3899314-khun-boo--af1b0991---3741706\n",
      "Error at https://propertyhub.in.th/en/listings/riviera-wongamat-sea-view-26f-1bedroom-thb18-000-month彡---3824063\n",
      "Error at https://propertyhub.in.th/en/listings/for-rentsupalai-park-srinakarin️line-0883894733--9d2608ea---3813629\n",
      "Error at https://propertyhub.in.th/en/listings/mb508-elements-srinakarin-beautiful-room-fully-furnished-beautifully-decorated-convenient-transportation-next-to-the-suan-luang-bts-station---3820227\n",
      "Error at https://propertyhub.in.th/en/listings/urgently-knightsbridge-phaholyothin-interchange-for-rent-18k-with-fully-furnished---3228035\n",
      "Thread 78: !!! Scraping completed (2 errors, 4 invalid links)\n",
      "Thread 74: !!! Scraping completed (4 errors, 6 invalid links)\n",
      "Thread 76: !!! Scraping completed (1 errors, 1 invalid links)\n",
      "Thread 73: !!! Scraping completed (2 errors, 6 invalid links)\n",
      "Thread 75: !!! Scraping completed (3 errors, 11 invalid links)\n",
      "Thread 77: !!! Scraping completed (2 errors, 2 invalid links)\n",
      "Thread 80: !!! Scraping completed (3 errors, 5 invalid links)\n",
      "Thread 79: !!! Scraping completed (4 errors, 19 invalid links)\n"
     ]
    }
   ],
   "source": [
    "# Scraping for-rent condo data\n",
    "rent_group_num = 80\n",
    "rent_links = []\n",
    "for i in range(rent_group_num):\n",
    "    start = round(i*len(df_rent_links)/rent_group_num)\n",
    "    end = round((i+1)*len(df_rent_links)/rent_group_num)\n",
    "    rent_links.append(df_rent_links.iloc[start:end,:])\n",
    "\n",
    "rent_thread_num = 16\n",
    "rent_scrape_threads = [ScrapeData() for _ in range(rent_thread_num)]\n",
    "rent_threadList = []\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    for i in range(rent_thread_num):\n",
    "        rent_threadList.append(executor.submit(rent_scrape_threads[i].main, rent_links[i+64], i+1+64, 1))\n",
    "wait(rent_threadList);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98a0527b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T21:43:11.104931Z",
     "iopub.status.busy": "2023-07-27T21:43:11.104572Z",
     "iopub.status.idle": "2023-07-27T21:43:14.017504Z",
     "shell.execute_reply": "2023-07-27T21:43:14.016281Z"
    },
    "papermill": {
     "duration": 2.920831,
     "end_time": "2023-07-27T21:43:14.019727",
     "exception": false,
     "start_time": "2023-07-27T21:43:11.098896",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total output length: 21731\n"
     ]
    }
   ],
   "source": [
    "# Read all files in the output folder\n",
    "output_files = glob.glob(f\"{os.getcwd()}/condo_data*.csv\")\n",
    "outputs = [pd.read_csv(f'{output_file}') for output_file in output_files]\n",
    "\n",
    "# Combine outputs\n",
    "output_all = outputs[0]\n",
    "for i in range(len(outputs)-1):\n",
    "    output_all = pd.concat([output_all,outputs[i+1]], axis=0, ignore_index=True)\n",
    "\n",
    "# Drop empty rows resulting from errors from scraping\n",
    "output_all.dropna(subset=['post_name'], axis=0, inplace=True)\n",
    "output_all.reset_index(inplace=True, drop=True)\n",
    "output = output_all\n",
    "\n",
    "# Export the combine result\n",
    "output.to_csv(f\"{datetime.now().strftime('%Y%m')}_condo_data_5.csv\",index=False)\n",
    "\n",
    "# Delete all the unused files\n",
    "[os.remove(output_file) for output_file in output_files];\n",
    "\n",
    "# Show results\n",
    "print(f'Total output length: {len(output)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 20971.945923,
   "end_time": "2023-07-27T21:43:15.378636",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-07-27T15:53:43.432713",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
